# ==============================
# 1. å¯¼å…¥å¿…è¦åº“
# ==============================
from ultralytics import YOLO
import cv2
import matplotlib.pyplot as plt
import os
from ultralytics.utils.plotting import plot_results
from ultralytics.utils.metrics import ConfusionMatrix
import shutil

# ==============================
# 2. é…ç½®å…¨å±€å‚æ•°ï¼ˆéœ€æ ¹æ®è‡ªèº«ç¯å¢ƒè°ƒæ•´ï¼‰
# ==============================
class Config:
    # æ•°æ®é›†é…ç½®ï¼ˆCOCOä¼šè‡ªåŠ¨ä¸‹è½½ï¼Œè·¯å¾„å¯è‡ªå®šä¹‰ï¼‰
    data_path = "./datasets/coco"  # æ•°æ®é›†ä¿å­˜è·¯å¾„
    coco_yaml = "coco128.yaml"     # ç®€åŒ–ç‰ˆCOCOï¼ˆ128å¼ å›¾ï¼Œå¿«é€Ÿæµ‹è¯•ï¼›æ­£å¼è®­ç»ƒç”¨"coco.yaml"ï¼‰
    
    # æ¨¡å‹é…ç½®
    model_type = "yolov8n.pt"      # YOLOv8 nanoï¼ˆè½»é‡ï¼Œé€‚åˆPCè®­ç»ƒï¼›å¯é€‰yolov8s/m/l/x.ptï¼‰
    trained_weights_path = "./runs/detect/train/weights/best.pt"  # è®­ç»ƒåæƒé‡ä¿å­˜è·¯å¾„
    
    # è®­ç»ƒé…ç½®
    epochs = 10                    # è®­ç»ƒè½®æ¬¡ï¼ˆæ­£å¼è®­ç»ƒå»ºè®®30-50ï¼‰
    batch_size = 4                 # æ‰¹æ¬¡å¤§å°ï¼ˆæ ¹æ®GPUæ˜¾å­˜è°ƒæ•´ï¼Œæ˜¾å­˜è¶³è®¾8-16ï¼‰
    img_size = 640                 # è¾“å…¥å›¾åƒå°ºå¯¸
    
    # ç»“æœä¿å­˜é…ç½®
    save_dir = "./assignment_results"  # ä½œä¸šç»“æœæ€»ç›®å½•
    vis_dir = f"{save_dir}/visualizations"  # å¯è§†åŒ–ç»“æœç›®å½•
    model_dir = f"{save_dir}/trained_model"  # è®­ç»ƒæ¨¡å‹ä¿å­˜ç›®å½•


# ==============================
# 3. åˆå§‹åŒ–ç›®å½•ï¼ˆç¡®ä¿ç»“æœä¿å­˜è·¯å¾„å­˜åœ¨ï¼‰
# ==============================
def init_dirs():
    dirs = [Config.save_dir, Config.vis_dir, Config.model_dir]
    for dir in dirs:
        if not os.path.exists(dir):
            os.makedirs(dir)
    print("âœ… æ‰€æœ‰ç»“æœç›®å½•åˆå§‹åŒ–å®Œæˆ")


# ==============================
# 4. æ•°æ®é¢„å¤„ç†ä¸å¯è§†åŒ–ï¼ˆæ»¡è¶³ä½œä¸š"æ•°æ®é¢„å¤„ç†"è¦æ±‚ï¼‰
# ==============================
def visualize_dataset_samples():
    """åŠ è½½COCOæ ·æœ¬å¹¶ç»˜åˆ¶è¾¹ç•Œæ¡†ï¼Œä¿å­˜å¯è§†åŒ–ç»“æœ"""
    # åŠ è½½YOLOæ•°æ®é›†ï¼ˆè‡ªåŠ¨è§£æCOCOæ ‡æ³¨ï¼‰
    from ultralytics.data import YOLODataset
    dataset = YOLODataset(
        img_path=os.path.join(Config.data_path, "train2017"),
        yaml_path=Config.coco_yaml,
        img_size=Config.img_size,
        augment=False  # ä¸å¢å¼ºï¼Œä»…å¯è§†åŒ–åŸå§‹æ ·æœ¬
    )
    
    # å¯è§†åŒ–5ä¸ªä¸åŒç±»åˆ«çš„æ ·æœ¬
    class_names = dataset.names  # COCOç±»åˆ«åç§°ï¼ˆå¦‚"person", "car"ï¼‰
    for i in range(5):
        img, targets, paths = dataset[i]  # è¯»å–å›¾åƒã€æ ‡æ³¨ã€è·¯å¾„
        img = img.permute(1, 2, 0).cpu().numpy()  # è½¬æ¢ä¸ºOpenCVæ ¼å¼ï¼ˆHWCï¼‰
        img = (img * 255).astype("uint8")  # åå½’ä¸€åŒ–ï¼ˆYOLOåŠ è½½æ—¶é»˜è®¤å½’ä¸€åŒ–åˆ°0-1ï¼‰
        
        # ç»˜åˆ¶è¾¹ç•Œæ¡†ï¼ˆtargetsæ ¼å¼ï¼š[class_id, x1, y1, x2, y2]ï¼Œç›¸å¯¹åæ ‡â†’ç»å¯¹åæ ‡ï¼‰
        h, w = img.shape[:2]
        for target in targets:
            cls_id, x1, y1, x2, y2 = target
            x1, y1 = int(x1 * w), int(y1 * h)
            x2, y2 = int(x2 * w), int(y2 * h)
            # ç”»æ¡†ï¼ˆçº¢è‰²ï¼Œçº¿å®½2ï¼‰+ å†™ç±»åˆ«åç§°ï¼ˆç™½è‰²æ–‡å­—ï¼Œé»‘è‰²èƒŒæ™¯ï¼‰
            cv2.rectangle(img, (x1, y1), (x2, y2), (0, 0, 255), 2)
            cls_name = class_names[int(cls_id)]
            cv2.putText(
                img, cls_name, (x1, y1-10), 
                cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 1, cv2.LINE_AA
            )
        
        # ä¿å­˜å¯è§†åŒ–ç»“æœ
        save_path = f"{Config.vis_dir}/dataset_sample_{i+1}.jpg"
        cv2.imwrite(save_path, cv2.cvtColor(img, cv2.COLOR_RGB2BGR))  # è½¬æ¢ä¸ºBGRï¼ˆOpenCVé»˜è®¤ï¼‰
    print(f"âœ… æ•°æ®é›†å¯è§†åŒ–å®Œæˆï¼Œç»“æœä¿å­˜åœ¨ {Config.vis_dir}")


# ==============================
# 5. æ¨¡å‹è®­ç»ƒï¼ˆæ»¡è¶³ä½œä¸š"æ¨¡å‹è®¾è®¡ä¸è®­ç»ƒ"è¦æ±‚ï¼‰
# ==============================
def train_model():
    """åŠ è½½YOLOv8æ¨¡å‹ï¼Œé…ç½®è®­ç»ƒå‚æ•°å¹¶å¼€å§‹è®­ç»ƒ"""
    # åŠ è½½é¢„è®­ç»ƒæ¨¡å‹ï¼ˆbackboneä¸ºCSPDarknetï¼Œç¬¦åˆä½œä¸š"backboneç½‘ç»œ"è¦æ±‚ï¼‰
    model = YOLO(Config.model_type)
    
    # å¼€å§‹è®­ç»ƒï¼ˆå†…ç½®åˆ†ç±»æŸå¤±+å›å½’æŸå¤±ï¼Œç¬¦åˆä½œä¸š"æŸå¤±å‡½æ•°"è¦æ±‚ï¼‰
    results = model.train(
        data=Config.coco_yaml,
        epochs=Config.epochs,
        batch=Config.batch_size,
        imgsz=Config.img_size,
        augment=True,  # å¯ç”¨æ•°æ®å¢å¼ºï¼ˆéšæœºç¿»è½¬ã€ç¼©æ”¾ç­‰ï¼Œç¬¦åˆä½œä¸š"æ•°æ®å¢å¼º"è¦æ±‚ï¼‰
        device=0,      # 0=ä½¿ç”¨GPUï¼Œ-1=ä½¿ç”¨CPUï¼ˆå»ºè®®ç”¨GPUï¼Œå¦åˆ™è®­ç»ƒææ…¢ï¼‰
        project=Config.save_dir,  # è®­ç»ƒç»“æœä¿å­˜æ ¹ç›®å½•
        name="train",  # è®­ç»ƒç»“æœå­ç›®å½•ï¼ˆä¼šè‡ªåŠ¨åˆ›å»ºï¼‰
        save=True,     # ä¿å­˜æ¨¡å‹æƒé‡
        val=True       # è®­ç»ƒä¸­è‡ªåŠ¨éªŒè¯
    )
    
    # ä¿å­˜è®­ç»ƒæ›²çº¿ï¼ˆæŸå¤±ã€mAPç­‰ï¼‰
    plot_results(results=results, save_dir=Config.vis_dir)
    print(f"âœ… æ¨¡å‹è®­ç»ƒå®Œæˆï¼è®­ç»ƒæ›²çº¿ä¿å­˜åœ¨ {Config.vis_dir}")
    print(f"âœ… æœ€ä½³æ¨¡å‹æƒé‡ä¿å­˜åœ¨ {Config.trained_weights_path}")


# ==============================
# 6. æ¨¡å‹è¯„ä¼°ï¼ˆæ»¡è¶³ä½œä¸š"æ¨¡å‹è¯„ä¼°ä¸åˆ†æ"è¦æ±‚ï¼‰
# ==============================
def evaluate_model():
    """ç”¨ COCO æµ‹è¯•é›†è¯„ä¼°æ¨¡å‹ï¼Œè®¡ç®— mAPï¼ˆä¸ä¾èµ– pycocotoolsï¼‰"""
    # åŠ è½½è®­ç»ƒå¥½çš„æ¨¡å‹
    model = YOLO(Config.trained_weights_path)
    
    # è®¡ç®—æ ‡å‡†æŒ‡æ ‡
    eval_results = model.val(
        data=Config.coco_yaml,
        split="test",
        imgsz=Config.img_size,
        device=0,
        verbose=True  # æ˜¾ç¤ºè¯¦ç»†è¯„ä¼°ç»“æœ
    )
    
    # æ‰“å°æ ¸å¿ƒè¯„ä¼°æŒ‡æ ‡ï¼ˆä½œä¸šè¦æ±‚çš„ mAP å·²åŒ…å«ï¼‰
    print("\n" + "="*50)
    print("ğŸ“Š æ¨¡å‹è¯„ä¼°ç»“æœï¼ˆCOCO æµ‹è¯•é›†ï¼‰")
    print(f"mAP@0.5: {eval_results.box.map:.4f}")       # ä½œä¸šæ ¸å¿ƒæŒ‡æ ‡
    print(f"mAP@0.5:0.95: {eval_results.box.map50_95:.4f}")  # æ‹“å±•æŒ‡æ ‡
    print(f"Precision: {eval_results.box.precision:.4f}")    # ç²¾åº¦
    print(f"Recall: {eval_results.box.recall:.4f}")          # å¬å›ç‡
    print("="*50 + "\n")
    
    # éš¾ä¾‹åˆ†æï¼ˆä¸å˜ï¼Œæ— éœ€ pycocotoolsï¼‰
    analyze_hard_cases(model)
    print(f"âœ… æ¨¡å‹è¯„ä¼°å®Œæˆï¼éš¾ä¾‹æ£€æµ‹ç»“æœä¿å­˜åœ¨ {Config.vis_dir}")
    
    # æ‰“å°è¯„ä¼°ç»“æœ
    print("\n" + "="*50)
    print("ğŸ“Š æ¨¡å‹è¯„ä¼°ç»“æœï¼ˆCOCOæµ‹è¯•é›†ï¼‰")
    print(f"mAP@0.5: {eval_results.box.map:.4f}")       # IoU=0.5æ—¶çš„mAP
    print(f"mAP@0.5:0.95: {eval_results.box.map50_95:.4f}")  # IoU=0.5-0.95çš„mAP
    print(f"Precision: {eval_results.box.precision:.4f}")    # ç²¾åº¦
    print(f"Recall: {eval_results.box.recall:.4f}")          # å¬å›ç‡
    print("="*50 + "\n")
    
    # 2. å¯è§†åŒ–æ··æ·†çŸ©é˜µï¼ˆåˆ†æç±»åˆ«çº§æ£€æµ‹æ•ˆæœï¼‰
    conf_matrix = ConfusionMatrix(model.names)
    conf_matrix.plot(save_dir=Config.vis_dir, fname="confusion_matrix.png")
    
    # 3. éš¾ä¾‹åˆ†æï¼ˆå°ç›®æ ‡ã€é®æŒ¡ç›®æ ‡ï¼‰
    analyze_hard_cases(model)
    print(f"âœ… æ¨¡å‹è¯„ä¼°å®Œæˆï¼æ··æ·†çŸ©é˜µä¿å­˜åœ¨ {Config.vis_dir}")


def analyze_hard_cases(model):
    """åˆ†æå°ç›®æ ‡ã€é®æŒ¡ç›®æ ‡ç­‰éš¾ä¾‹ï¼Œä¿å­˜æ£€æµ‹ç»“æœ"""
    # åŠ è½½COCOæµ‹è¯•é›†ä¸­çš„éš¾ä¾‹ï¼ˆè¿™é‡Œç”¨10å¼ å«å°ç›®æ ‡/é®æŒ¡çš„æ ·æœ¬ï¼Œå¯è‡ªå®šä¹‰è·¯å¾„ï¼‰
    test_img_paths = [
        os.path.join(Config.data_path, "test2017", f"{i:012d}.jpg") 
        for i in range(100000, 100010)  # COCOæµ‹è¯•é›†å›¾åƒIDï¼ˆç¤ºä¾‹ï¼‰
    ]
    
    for img_path in test_img_paths:
        if not os.path.exists(img_path):
            continue
        
        # æ£€æµ‹å›¾åƒ
        results = model.predict(
            source=img_path,
            imgsz=Config.img_size,
            conf=0.25,  # ç½®ä¿¡åº¦é˜ˆå€¼ï¼ˆè¿‡æ»¤ä½ç½®ä¿¡åº¦é¢„æµ‹ï¼‰
            iou=0.5     # IoUé˜ˆå€¼ï¼ˆéæå¤§å€¼æŠ‘åˆ¶ï¼‰
        )
        
        # ä¿å­˜æ£€æµ‹ç»“æœï¼ˆå«è¾¹ç•Œæ¡†å’Œç±»åˆ«æ ‡ç­¾ï¼‰
        img = results[0].plot()  # è‡ªåŠ¨ç»˜åˆ¶æ£€æµ‹æ¡†
        img_name = os.path.basename(img_path)
        save_path = f"{Config.vis_dir}/hard_case_{img_name}"
        cv2.imwrite(save_path, img)
    
    print(f"âœ… éš¾ä¾‹åˆ†æå®Œæˆï¼éš¾ä¾‹æ£€æµ‹ç»“æœä¿å­˜åœ¨ {Config.vis_dir}")


# ==============================
# 7. æ¨¡å‹ä¿å­˜ä¸æäº¤ææ–™æ•´ç†ï¼ˆæ»¡è¶³ä½œä¸š"æäº¤ææ–™"è¦æ±‚ï¼‰
# ==============================
def organize_submission_materials():
    """æ•´ç†ä½œä¸šæäº¤ææ–™ï¼šä»£ç ã€æ¨¡å‹æƒé‡ã€å¯è§†åŒ–ã€æŠ¥å‘Šæ¨¡æ¿"""
    # 1. å¤åˆ¶è®­ç»ƒå¥½çš„æ¨¡å‹åˆ°æŒ‡å®šç›®å½•
    if os.path.exists(Config.trained_weights_path):
        shutil.copy(Config.trained_weights_path, Config.model_dir)
        # å¤åˆ¶æ¨¡å‹é…ç½®æ–‡ä»¶ï¼ˆYOLOv8é…ç½®ï¼‰
        shutil.copy(
            os.path.join(os.path.dirname(Config.trained_weights_path), "args.yaml"),
            Config.model_dir
        )
    
    # 2. ä¿å­˜ä»£ç æ–‡ä»¶ï¼ˆå½“å‰è„šæœ¬ï¼‰
    shutil.copy(__file__, Config.save_dir)
    
    # 3. ç”Ÿæˆå®éªŒæŠ¥å‘Šæ¨¡æ¿ï¼ˆMarkdownæ ¼å¼ï¼Œç”¨æˆ·éœ€è¡¥å……ç»†èŠ‚ï¼‰
    report_content = """# ç›®æ ‡æ£€æµ‹ä½œä¸šå®éªŒæŠ¥å‘Š
## 1. æ•°æ®é›†ä»‹ç»
- é‡‡ç”¨æ•°æ®é›†ï¼šCOCO 2017
- è®­ç»ƒé›†è§„æ¨¡ï¼š118k imagesï¼ˆæ­£å¼è®­ç»ƒï¼‰/ 128 imagesï¼ˆæµ‹è¯•ï¼‰
- ç±»åˆ«æ•°é‡ï¼š80ç±»
- æ ‡æ³¨ç±»å‹ï¼šè¾¹ç•Œæ¡†ï¼ˆbounding boxï¼‰

## 2. æ¨¡å‹è®¾è®¡
- æ¨¡å‹æ¶æ„ï¼šYOLOv8ï¼ˆå•é˜¶æ®µæ£€æµ‹å™¨ï¼‰
- Backboneï¼šCSPDarknet
- æ£€æµ‹å¤´ï¼šå¤šå°ºåº¦æ£€æµ‹å¤´ï¼ˆæ”¯æŒå°/ä¸­/å¤§ç›®æ ‡æ£€æµ‹ï¼‰
- æŸå¤±å‡½æ•°ï¼šåˆ†ç±»æŸå¤±ï¼ˆäº¤å‰ç†µï¼‰+ å›å½’æŸå¤±ï¼ˆCIoUï¼‰

## 3. è®­ç»ƒè¿‡ç¨‹
- è¶…å‚æ•°ï¼šepochs={}, batch_size={}, img_size={}
- ä¼˜åŒ–å™¨ï¼šAdamW
- æ•°æ®å¢å¼ºï¼šéšæœºæ°´å¹³ç¿»è½¬ã€å°ºåº¦ç¼©æ”¾ã€äº®åº¦è°ƒæ•´
- è®­ç»ƒæŸå¤±æ›²çº¿ï¼šè§ visualizations/results.png

## 4. è¯„ä¼°ç»“æœ
- mAP@0.5ï¼š{}ï¼ˆéœ€è¡¥å……å®é™…æ•°å€¼ï¼‰
- mAP@0.5:0.95ï¼š{}ï¼ˆéœ€è¡¥å……å®é™…æ•°å€¼ï¼‰
- éš¾ä¾‹åˆ†æï¼š
  - å°ç›®æ ‡ï¼šæ£€æµ‹ç²¾åº¦è¾ƒä½ï¼ˆå› ç‰¹å¾æå–ä¸å……åˆ†ï¼‰
  - é®æŒ¡ç›®æ ‡ï¼šé®æŒ¡ç‡>50%æ—¶æ˜“æ¼æ£€ï¼ˆå› ç›®æ ‡ç‰¹å¾ä¸å®Œæ•´ï¼‰

## 5. æ”¹è¿›æ–¹å‘
1. å¢åŠ å°ç›®æ ‡æ ·æœ¬çš„æ•°æ®å¢å¼ºï¼ˆå¦‚è¿‡é‡‡æ ·ï¼‰
2. èåˆä¸Šä¸‹æ–‡ç‰¹å¾ï¼ˆå¦‚åŠ å…¥æ³¨æ„åŠ›æœºåˆ¶ï¼‰
3. è°ƒæ•´ç½®ä¿¡åº¦é˜ˆå€¼ä»¥å¹³è¡¡ç²¾åº¦å’Œå¬å›ç‡
""".format(Config.epochs, Config.batch_size, Config.img_size, "?", "?")
    
    # ä¿å­˜æŠ¥å‘Šæ¨¡æ¿
    with open(f"{Config.save_dir}/experiment_report.md", "w", encoding="utf-8") as f:
        f.write(report_content)
    
    print(f"âœ… æäº¤ææ–™æ•´ç†å®Œæˆï¼æ‰€æœ‰ææ–™ä¿å­˜åœ¨ {Config.save_dir}")
    print("\nğŸ“‹ æäº¤ææ–™æ¸…å•ï¼š")
    print(f"1. ä»£ç ï¼š{Config.save_dir}/{os.path.basename(__file__)}")
    print(f"2. æ¨¡å‹æƒé‡ï¼š{Config.model_dir}/best.pt")
    print(f"3. å®éªŒæŠ¥å‘Šï¼š{Config.save_dir}/experiment_report.md")
    print(f"4. å¯è§†åŒ–ç»“æœï¼š{Config.vis_dir}ï¼ˆæ ·æœ¬å›¾ã€è®­ç»ƒæ›²çº¿ã€æ··æ·†çŸ©é˜µã€éš¾ä¾‹åˆ†æï¼‰")


# ==============================
# 8. ä¸»å‡½æ•°ï¼ˆæŒ‰æµç¨‹æ‰§è¡Œæ‰€æœ‰æ­¥éª¤ï¼‰
# ==============================
if __name__ == "__main__":
    # æ­¥éª¤1ï¼šåˆå§‹åŒ–ç›®å½•
    init_dirs()
    
    # æ­¥éª¤2ï¼šæ•°æ®é›†å¯è§†åŒ–
    visualize_dataset_samples()
    
    # æ­¥éª¤3ï¼šæ¨¡å‹è®­ç»ƒï¼ˆè€—æ—¶è¾ƒé•¿ï¼ŒGPUçº¦1-2å°æ—¶/10è½®ï¼‰
    train_model()
    
    # æ­¥éª¤4ï¼šæ¨¡å‹è¯„ä¼°
    evaluate_model()
    
    # æ­¥éª¤5ï¼šæ•´ç†æäº¤ææ–™
    organize_submission_materials()
    
    print("\nğŸ‰ ç›®æ ‡æ£€æµ‹ä½œä¸šä»£ç å…¨éƒ¨æ‰§è¡Œå®Œæˆï¼è¯·æ£€æŸ¥ submission_results ç›®å½•å‡†å¤‡æäº¤ã€‚")